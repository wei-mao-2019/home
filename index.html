<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Wei Mao</title>
  
  <meta name="author" content="Wei Mao">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Wei Mao ÊØõ‰ºü</name>
              </p>
              <p>I am a postdoc at <a href="https://www.anu.edu.au">Australian National University (ANU)</a> advised by <a href="https://users.cecs.anu.edu.au/~hartley/">Prof. Richard Hartley</a>, and <a href="https://users.cecs.anu.edu.au/~mliu/">Dr. Miaomiao Liu</a>. I also work closely with <a href="https://people.epfl.ch/mathieu.salzmann">Dr. Mathieu Salzmann</a> from EPFL. My research interests mainly lie in two folds: human motion understanding including human motion prediction/generation, human-scene interaction; 3D vision including 3D reconstuction of dynamic scenes, neural rendering, and depth estimation. I obtained my Ph.D. from ANU in 2022 supervised by Dr Miaomiao Liu. Prior to that I received a master degree in Computing from ANU in 2018, and a Bachelor of Engineering from East China University of Science and Technology (ECUST) in 2013, respectively.
              </p>
              <p style="text-align:center">
                <a href="mailto:wei.mao@anu.edu.au">Email</a> &nbsp/&nbsp
                <a href="data/wei_cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com.au/citations?user=X3ji--4AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/wei-mao-2019/">Github</a>&nbsp/&nbsp
                <a href="https://www.linkedin.com/in/wei-mao-anu/">Linkedin</a>
              </p>
              <p>
                <FONT COLOR=red>
                I'm actively looking for fulltime researcher positions.
                </FONT>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/wei.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/wei-circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
                <ul>
                    <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">09/2023: One paper has been accepted to NeurIPS2023, Congrates to Rong. </li>
                    <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">03/2023: One paper has been accepted to CVPR2023, Congrates to Huiyu. </li>
                    <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">12/2022: My PhD thesis titled "Human Motion Prediction: From Deterministic to Stochastic" has been published (<a href="https://openresearch-repository.anu.edu.au/handle/1885/282314">here</a>). </li>
                    <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">10/2022: Our paper "Contact-aware Human Motion Forecasting" has been accepted to NeurIPS2022</li>
                    <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">03/2022: One paper accepted to CVPR2022 (oral)</li>
                    <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">01/2022: I will work as a Postdoc with <a href="https://users.cecs.anu.edu.au/~hartley/">Prof. Richard Hartley</a> and <a href="https://users.cecs.anu.edu.au/~mliu/">Dr. Miaomiao Liu</a> after finishing my PhD !!!</li>
                    <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">07/2021: One paper has been accepted to ICCV2021 (oral)</li>
                    <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">03/2020: One paper has been accepted to CVPR2020 (oral). Congrates to Jiayu.</li>
<!--                    <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">07/2020: One paper has been accepted to ECCV2020</li>-->
<!--                    <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">07/2019: One paper has been accepted to ICCV2019 (oral)</li>-->
                </ul>
              </p>
            </td>
          </tr>
        </tbody>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I have broad interests in human related research and 3D vision.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr onmouseout="visfusion_stop()" onmouseover="visfusion_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div id='vis_ani' class='hidden'><img src="images/cvpr23_visfusion.gif" width="160"></div>
                <div id='vis_img'>
                  <a href="images/cvpr23_visfusion.gif"><img src="images/cvpr23_visfusion.jpg" width="160"></a>
                </div>
                <script type="text/javascript">
                  function visfusion_start() {
                    document.getElementById('vis_ani').style.display = 'inline';
                    document.getElementById('vis_img').style.display = 'none';
                  }

                  function visfusion_stop() {
                    document.getElementById('vis_ani').style.display = 'none';
                    document.getElementById('vis_img').style.display = 'inline';
                  }
                  visfusion_stop()
                </script>
              </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2304.10687">
                <papertitle>VisFusion: Visibility-aware Online 3D Scene Reconstruction from Videos
              </a>
              <br>
              <a href="https://github.com/huiyu-gao">Huiyu Gao</a>,
              <strong>Wei Mao</strong>,
              <a href="https://users.cecs.anu.edu.au/~mliu/">Miaomiao Liu</a>
              <br>
              <em>CVPR</em>, 2023 &nbsp;
              <br>
              <a href="https://arxiv.org/abs/2304.10687">arXiv</a> /
              <a href="https://huiyu-gao.github.io/visfusion/">project page</a> /
              <a href="https://github.com/huiyu-gao/VisFusion">code</a>
              <p></p>
              <p>Estimating visibility aware feature volume with ray-based sparsification for volumetric-based 3D reconstruction.</p>
            </td>
          </tr>
          <tr onmouseout="denseatt_stop()" onmouseover="denseatt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='denseatt_ani' class='hidden'><img src="images/wacv23_denseatt.gif" width="160"></div>
              <div id='denseatt_img'>
                <a href="images/wacv23_denseatt.gif"><img src="images/wacv23_denseatt.jpg" width="160"></a>
              </div>
              <script type="text/javascript">
                function denseatt_start() {
                  document.getElementById('denseatt_ani').style.display = 'inline';
                  document.getElementById('denseatt_img').style.display = 'none';
                }

                function denseatt_stop() {
                  document.getElementById('denseatt_ani').style.display = 'none';
                  document.getElementById('denseatt_img').style.display = 'inline';
                }
                denseatt_stop()
              </script>
            </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://openaccess.thecvf.com/content/WACV2023/html/Wang_Interacting_Hand-Object_Pose_Estimation_via_Dense_Mutual_Attention_WACV_2023_paper.html">
              <papertitle>Interacting Hand-Object Pose Estimation via Dense Mutual Attention
            </a>
            <br>
            <a href="https://github.com/rongakowang">Rong Wang</a>,
            <strong>Wei Mao</strong>,
            <a href="https://users.cecs.anu.edu.au/~hongdong/">Hongdong Li</a>
            <br>
            <em>WACV</em>, 2023 &nbsp;
            <br>
            <a href="https://arxiv.org/abs/2211.08805">arXiv</a> /
            <a href="https://www.youtube.com/watch?v=dQfK8nb-0i8">video</a> /
            <a href="https://github.com/rongakowang/DenseMutualAttention">code</a>
            <p></p>
            <p>Mutual attention between hand and object for hand object pose estimation.</p>
          </td>
        </tr>

          <tr onmouseout="cont_stop()" onmouseover="cont_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='cont_ani' class='hidden'><img src="images/cont.gif" width="160"></div>
              <div id='cont_img'>
                <a href="images/cont.gif"><img src="images/cont.jpg" width="160"></a>
              </div>
              <script type="text/javascript">
                function cont_start() {
                  document.getElementById('cont_ani').style.display = 'inline';
                  document.getElementById('cont_img').style.display = 'none';
                }

                function cont_stop() {
                  document.getElementById('cont_ani').style.display = 'none';
                  document.getElementById('cont_img').style.display = 'inline';
                }
                cont_stop()
              </script>
            </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2210.03954">
              <papertitle>Contact-aware Human Motion Forecasting</papertitle>
            </a>
            <br>
            <strong>Wei Mao</strong>,
            <a href="https://users.cecs.anu.edu.au/~mliu/">Miaomiao Liu</a>,
            <a href="https://users.cecs.anu.edu.au/~hartley/">Richard Hartley</a>,
            <a href="https://people.epfl.ch/mathieu.salzmann">Mathieu Salzmann</a>
            <br>
            <em>NeurIPS</em>, 2022 &nbsp; <font color="red"><strong>(Spotlight)</strong></font>
            <br>
            <a href="https://arxiv.org/abs/2210.03954">arXiv</a> /
            <a href="https://neurips.cc/virtual/2022/poster/54945">video</a> /
            <a href="https://github.com/wei-mao-2019/ContAwareMotionPred">code</a>
            <p></p>
            <p>Predicting per-joint contact maps for human motion forecasting.</p>
          </td>
        </tr>
            <tr onmouseout="wat_stop()" onmouseover="wat_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div id='wat_ani' class='hidden'><img src="images/wat.gif" width="160"></div>
                <div id='wat_img'>
                  <a href="images/wat.gif"><img src="images/wat.jpg" width="160"></a>
                </div>
                <script type="text/javascript">
                  function wat_start() {
                    document.getElementById('wat_ani').style.display = 'inline';
                    document.getElementById('wat_img').style.display = 'none';
                  }

                  function wat_stop() {
                    document.getElementById('wat_ani').style.display = 'none';
                    document.getElementById('wat_img').style.display = 'inline';
                  }
                    wat_stop()
                </script>
              </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2205.15608">
                <papertitle>Weakly-supervised Action Transition Learning for Stochastic Human Motion Prediction</papertitle>
              </a>
              <br>
              <strong>Wei Mao</strong>,
              <a href="https://users.cecs.anu.edu.au/~mliu/">Miaomiao Liu</a>,
              <a href="https://people.epfl.ch/mathieu.salzmann">Mathieu Salzmann</a>
              <br>
              <em>CVPR</em>, 2022 &nbsp; <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
							<a href="https://arxiv.org/abs/2205.15608">arXiv</a> /
							<a href="https://youtu.be/OyG8-DVJfAQ">video</a> /
							<a href="https://github.com/wei-mao-2019/WAT">code</a>
              <p></p>
              <p>Generating diverse human motion with a sequence of action labels.</p>
            </td>
          </tr>
          <tr onmouseout="gsps_stop()" onmouseover="gsps_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='gsps_ani' class='hidden'><img src="images/gsps.gif" width="160"></div>
              <div id='gsps_img'>
                <a href="images/wat.gif"><img src="images/gsps.jpg" width="160"></a>
              </div>
              <script type="text/javascript">
                function gsps_start() {
                  document.getElementById('gsps_ani').style.display = 'inline';
                  document.getElementById('gsps_img').style.display = 'none';
                }

                function gsps_stop() {
                  document.getElementById('gsps_ani').style.display = 'none';
                  document.getElementById('gsps_img').style.display = 'inline';
                }
                  gsps_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://arxiv.org/abs/2108.08422">
                <papertitle>Generating Smooth Pose Sequences for Diverse Human Motion Prediction</papertitle>
              </a>
              <br>
              <strong>Wei Mao</strong>,
              <a href="https://users.cecs.anu.edu.au/~mliu/">Miaomiao Liu</a>,
              <a href="https://people.epfl.ch/mathieu.salzmann">Mathieu Salzmann</a>
              <br>
              <em>ICCV</em>, 2021 &nbsp; <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
                            <a href="https://arxiv.org/abs/2108.08422">arXiv</a> /
                            <a href="https://youtu.be/_KgYdosouUs">video</a> /
                            <a href="https://github.com/wei-mao-2019/gsps">code</a>
              <p></p>
              <p>A model to predict diverse human motions without diverse training samples.</p>
            </td>
          </tr>
          <tr onmouseout="ma_stop()" onmouseover="ma_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='ma_gif' class='hidden'><img src="images/ma.gif" width="160"></div>
              <div id='ma_img'>
                <a href="images/ma.gif"><img src="images/ma.jpg"  width="160"></a>
              </div>
              <script type="text/javascript">
                function ma_start() {
                  document.getElementById('ma_gif').style.display = 'inline';
                  document.getElementById('ma_img').style.display = 'none';
                }

                function ma_stop() {
                  document.getElementById('ma_gif').style.display = 'none';
                  document.getElementById('ma_img').style.display = 'inline';
                }
                  ma_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://arxiv.org/abs/2007.11755">
                <papertitle>History Repeats Itself: Human Motion Prediction via Motion Attention</papertitle>
              </a>
              <br>
              <strong>Wei Mao</strong>,
              <a href="https://users.cecs.anu.edu.au/~mliu/">Miaomiao Liu</a>,
              <a href="https://people.epfl.ch/mathieu.salzmann">Mathieu Salzmann</a>
              <br>
              <em>ECCV</em>, 2020
              <br>
                            <a href="https://arxiv.org/abs/2007.11755">arXiv</a> /
                            <a href="https://youtu.be/VMQowdWHAM4">video</a> /
                            <a href="https://github.com/wei-mao-2019/HisRepItself">code</a>
              <p></p>
              <p>Capture similar motion pattern with motion attention.</p>
            </td>
          </tr>
          
          <tr onmouseout="cvp_stop()" onmouseover="cvp_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='cvp_gif' class='hidden'><img src="images/cvp.gif" width="160"></div>
              <div id='cvp_img'>
                <a href="images/cvp.gif"><img src="images/cvp.jpg"  width="160"></a>
              </div>
              <script type="text/javascript">
                function cvp_start() {
                  document.getElementById('cvp_gif').style.display = 'inline';
                  document.getElementById('cvp_img').style.display = 'none';
                }

                function cvp_stop() {
                  document.getElementById('cvp_gif').style.display = 'none';
                  document.getElementById('cvp_img').style.display = 'inline';
                }
                  cvp_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://arxiv.org/abs/1912.08329">
                <papertitle>Cost Volume Pyramid Based Depth Inference for Multi-View Stereo</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com.au/citations?user=xe6Uv3gAAAAJ&hl=en&oi=ao">Jiayu Yang</a>,
              <strong>Wei Mao</strong>,
              <a href="https://alvarezlopezjosem.github.io/">Jose M. Alvarez</a>,
              <a href="https://users.cecs.anu.edu.au/~mliu/">Miaomiao Liu</a>
              <br>
              <em>CVPR</em>, 2020 &nbsp; <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
                            <a href="https://arxiv.org/abs/1912.08329">arXiv</a> /
                            <a href="https://www.youtube.com/watch?v=lBFgNyz5JpU&ab_channel=ComputerVisionFoundationVideos">video</a> /
                            <a href="https://github.com/JiayuYANG/CVP-MVSNet">code</a>
              <p></p>
              <p>A coarse-to-fine approach for multi-view stereo.</p>
            </td>
          </tr>
          <tr onmouseout="ltd_stop()" onmouseover="ltd_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='ltd_gif' class='hidden'><img src="images/ltd.gif" width="160"></div>
              <div id='ltd_img'>
                <a href="images/ltd.gif"><img src="images/ltd.jpg"  width="160"></a>
              </div>
              <script type="text/javascript">
                function ltd_start() {
                  document.getElementById('ltd_gif').style.display = 'inline';
                  document.getElementById('ltd_img').style.display = 'none';
                }

                function ltd_stop() {
                  document.getElementById('ltd_gif').style.display = 'none';
                  document.getElementById('ltd_img').style.display = 'inline';
                }
                  ltd_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://arxiv.org/abs/1908.05436">
                <papertitle>Learning Trajectory Dependencies for Human Motion Prediction</papertitle>
              </a>
              <br>
              <strong>Wei Mao</strong>,
              <a href="https://users.cecs.anu.edu.au/~mliu/">Miaomiao Liu</a>,
              <a href="https://people.epfl.ch/mathieu.salzmann">Mathieu Salzmann</a>
              <a href="https://users.cecs.anu.edu.au/~hongdong/">Hongdong Li</a>
              <br>
              <em>ICCV</em>, 2019 &nbsp; <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
                            <a href="https://arxiv.org/abs/1908.05436">arXiv</a> /
                            <a href="https://youtu.be/3m49vQ6CUG4">video</a> /
                            <a href="https://github.com/wei-mao-2019/LearnTrajDep">code</a>
              <p></p>
              <p>Human motion prediction using DCT for temporal encoding and GCN for spatial encoding.</p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Website template is from  <a href="https://https://jonbarron.info/">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
